{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/Bao02Harry/Reognize_Rock_Paper_Scissors_Application/blob/main/SmallRPSDataset-master.zip?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mplimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "local_zip = './SmallRPSDataset-master.zip?raw=true'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./SmallRPSDataset-master')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with our training rock picture\n",
    "train_rock_dir = os.path.join(\"./SmallRPSDataset-master/rock\")\n",
    "# Directory with our training paper picture\n",
    "train_paper_dir = os.path.join(\"./SmallRPSDataset-master/paper\")\n",
    "# Directory with our training scissors picture\n",
    "train_scissors_dir = os.path.join(\"./SmallRPSDataset-master/scissors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rock_names = os.listdir(train_rock_dir)\n",
    "train_paper_names = os.listdir(train_paper_dir)\n",
    "train_scissors_names = os.listdir(train_scissors_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "299\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "print(len(train_rock_names))\n",
    "print(len(train_paper_names))\n",
    "print(len(train_scissors_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model= tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (300, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # This is the second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # This is the third convolution \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # This is the forth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # This is the fifth convolution convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horse) and 1 for the orther('humans')\n",
    "    tf.keras.layers.Dense(3, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= 'adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# All images will be rescaled by 1/255\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './SmallRPSDataset-master/SmallRPSDataset-master/', # This is the source directory for training images\n",
    "    target_size= (300, 200), # All images will be resized to 300x300\n",
    "    batch_size = 128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20\n",
    "np.random.seed(seed)\n",
    "history = model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "uploaded = files.upload()\n",
    "# uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = '/content/' + fn\n",
    "  img = image.load_img(path, target_size=(300, 200))\n",
    "  x = image.img_to_array(img)\n",
    "  x /= 255\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  classes = model.predict(images, batch_size=10)\n",
    "  print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index_row = np.argmax(np.array(classes), axis=1)\n",
    "print(max_index_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ad10527c7cbb7ca1b130671cbf296f0efbfc3869823047f289f53e7151b215b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
